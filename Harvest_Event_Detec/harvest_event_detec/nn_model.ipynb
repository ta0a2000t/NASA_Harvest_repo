{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-21 08:09:27.963791: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import geopandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO try only with best performing numeric columns for input into model first\n",
    "# TODO select features for deep learning model after ranking features with random forest (feature importance)\n",
    "# TODO lstm network\n",
    "# TODO SMOTE algorithm, for upsampling havested fields; we only have ~300 :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#local scripts\n",
    "from scripts import veg_indices, utilities, plots\n",
    "#from scripts.utilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cpied from learning_about-data.ipynb\n",
    "BANDS_DICT = {   'B2': 'Blue',\n",
    "            'B3': 'Green',\n",
    "            'B4': 'Red',\n",
    "            'B5': 'Red_Edge_1',\n",
    "            'B6': 'Red_Edge_2',\n",
    "            'B7': 'Red_Edge_3',\n",
    "            'B8': 'NIR',\n",
    "            'B8A': 'Red_Edge_4',\n",
    "            'B11': 'SWIR_1',\n",
    "            'B12': 'SWIR_2'}\n",
    "\n",
    "BANDS = list(BANDS_DICT.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cpied from learning_about-data.ipynb\n",
    "DF = geopandas.read_file('../data/merged_images.geojson')\n",
    "DF.rename(columns = {'is_within_period':'har_evnt'}, inplace = True)\n",
    "NUM_SAMPLES = len(np.unique(DF.image_idx)) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added:  ['DVI', 'RVI', 'ARVI', 'NDI45', 'GNDVI', 'MCARI', 'MTCI', 'NDTI', 'NDMI', 'MSI', 'GCI', 'NBRI', 'BSI', 'NDWI', 'NDSI']\n",
      "Added:  ['sample_idx', 'DVI_diff', 'RVI_diff', 'ARVI_diff', 'NDI45_diff', 'GNDVI_diff', 'MCARI_diff', 'MTCI_diff', 'NDTI_diff', 'NDMI_diff', 'MSI_diff', 'GCI_diff', 'NBRI_diff', 'BSI_diff', 'NDWI_diff', 'NDSI_diff', 'NDVI_diff']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Index(['B11', 'B12', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'NDVI',\n",
       "        'finHarvDat', 'lat', 'lon', 'point_idx', 'start_date', 'end_date',\n",
       "        'har_evnt', 'image_idx', 'geometry', 'DVI', 'RVI', 'ARVI', 'NDI45',\n",
       "        'GNDVI', 'MCARI', 'MTCI', 'NDTI', 'NDMI', 'MSI', 'GCI', 'NBRI', 'BSI',\n",
       "        'NDWI', 'NDSI', 'pt_idx', 'img_idx', 'DVI_diff', 'RVI_diff',\n",
       "        'ARVI_diff', 'NDI45_diff', 'GNDVI_diff', 'MCARI_diff', 'MTCI_diff',\n",
       "        'NDTI_diff', 'NDMI_diff', 'MSI_diff', 'GCI_diff', 'NBRI_diff',\n",
       "        'BSI_diff', 'NDWI_diff', 'NDSI_diff', 'NDVI_diff', 'sample_idx'],\n",
       "       dtype='object'),\n",
       " (6678, 54))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cpied from learning_about-data.ipynb\n",
    "df = DF.copy()\n",
    "df = df[(df.NDVI) != 0] # drop invalid points\n",
    "VEG_INDICES_NAMES = veg_indices.add_veg_indices(df) + ['NDVI'] \n",
    "VEG_DIFF_NAMES = veg_indices.add_veg_diff(df, VEG_INDICES_NAMES)\n",
    "NUMERIC_COLS = BANDS + VEG_INDICES_NAMES + VEG_DIFF_NAMES\n",
    "df = df.dropna(subset=['sample_idx']) # removes the first image, because sample_idx is NaN there\n",
    "df.columns, df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO look at samples(aka image2s) one by one\n",
    "\n",
    "# each sample_idx is an sample\n",
    "samples = np.array([1, 2, 3])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m np\u001b[39m.\u001b[39mconcatenate([sample])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sample' is not defined"
     ]
    }
   ],
   "source": [
    "np.concatenate([sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [2],\n",
       "       [3]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.newaxis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [2],\n",
       "       [3]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.reshape(samples, samples.shape + (1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_0 = np.array(df[df[\"sample_idx\"] == 's0'][[\"B2\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero = np.reshape(sample_0, sample_0.shape + (1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_1 = np.array(df[df[\"sample_idx\"] == 's1'][[\"B2\"]].head())\n",
    "one = np.reshape(sample_1, sample_1.shape + (1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.8832 ]],\n",
       "\n",
       "       [[0.0392 ]],\n",
       "\n",
       "       [[0.0294 ]],\n",
       "\n",
       "       [[0.86005]],\n",
       "\n",
       "       [[0.0455 ]],\n",
       "\n",
       "       [[0.0282 ]],\n",
       "\n",
       "       [[0.0226 ]],\n",
       "\n",
       "       [[0.025  ]],\n",
       "\n",
       "       [[0.0338 ]],\n",
       "\n",
       "       [[0.0425 ]]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate([zero, one])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6350.,  328.], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookupTable, indexed_dataSet = np.unique(df.har_evnt, return_inverse=True)\n",
    "np.sum(tf.keras.utils.to_categorical(indexed_dataSet), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 1., ..., 0., 1., 0.],\n",
       "       [1., 0., 0., ..., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpls = tf.keras.utils.to_categorical(indexed_dataSet)\n",
    "np.reshape(tpls, ( (2, -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6350.,  328.], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.array(list(zip(*tpls))), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6678, 2)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpls.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_idx</th>\n",
       "      <th>point_idx</th>\n",
       "      <th>har_evnt</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>finHarvDat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>s0</td>\n",
       "      <td>p10</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-01-29</td>\n",
       "      <td>2022-02-18</td>\n",
       "      <td>2022-07-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>s1</td>\n",
       "      <td>p10</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-02-19</td>\n",
       "      <td>2022-03-11</td>\n",
       "      <td>2022-07-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1684</th>\n",
       "      <td>s2</td>\n",
       "      <td>p10</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-03-12</td>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>2022-07-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2242</th>\n",
       "      <td>s3</td>\n",
       "      <td>p10</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-04-02</td>\n",
       "      <td>2022-04-22</td>\n",
       "      <td>2022-07-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2800</th>\n",
       "      <td>s4</td>\n",
       "      <td>p10</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-04-23</td>\n",
       "      <td>2022-05-13</td>\n",
       "      <td>2022-07-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3358</th>\n",
       "      <td>s5</td>\n",
       "      <td>p10</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-05-14</td>\n",
       "      <td>2022-06-03</td>\n",
       "      <td>2022-07-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3916</th>\n",
       "      <td>s6</td>\n",
       "      <td>p10</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-06-04</td>\n",
       "      <td>2022-06-24</td>\n",
       "      <td>2022-07-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4474</th>\n",
       "      <td>s7</td>\n",
       "      <td>p10</td>\n",
       "      <td>True</td>\n",
       "      <td>2022-06-25</td>\n",
       "      <td>2022-07-15</td>\n",
       "      <td>2022-07-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5032</th>\n",
       "      <td>s8</td>\n",
       "      <td>p10</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-07-16</td>\n",
       "      <td>2022-08-05</td>\n",
       "      <td>2022-07-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5590</th>\n",
       "      <td>s9</td>\n",
       "      <td>p10</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-08-06</td>\n",
       "      <td>2022-08-26</td>\n",
       "      <td>2022-07-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6148</th>\n",
       "      <td>s10</td>\n",
       "      <td>p10</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-08-27</td>\n",
       "      <td>2022-09-16</td>\n",
       "      <td>2022-07-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7264</th>\n",
       "      <td>s12</td>\n",
       "      <td>p10</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-10-08</td>\n",
       "      <td>2022-10-28</td>\n",
       "      <td>2022-07-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7822</th>\n",
       "      <td>s13</td>\n",
       "      <td>p10</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-10-29</td>\n",
       "      <td>2022-11-18</td>\n",
       "      <td>2022-07-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sample_idx point_idx  har_evnt start_date   end_date finHarvDat\n",
       "568          s0       p10     False 2022-01-29 2022-02-18 2022-07-14\n",
       "1126         s1       p10     False 2022-02-19 2022-03-11 2022-07-14\n",
       "1684         s2       p10     False 2022-03-12 2022-04-01 2022-07-14\n",
       "2242         s3       p10     False 2022-04-02 2022-04-22 2022-07-14\n",
       "2800         s4       p10     False 2022-04-23 2022-05-13 2022-07-14\n",
       "3358         s5       p10     False 2022-05-14 2022-06-03 2022-07-14\n",
       "3916         s6       p10     False 2022-06-04 2022-06-24 2022-07-14\n",
       "4474         s7       p10      True 2022-06-25 2022-07-15 2022-07-14\n",
       "5032         s8       p10     False 2022-07-16 2022-08-05 2022-07-14\n",
       "5590         s9       p10     False 2022-08-06 2022-08-26 2022-07-14\n",
       "6148        s10       p10     False 2022-08-27 2022-09-16 2022-07-14\n",
       "7264        s12       p10     False 2022-10-08 2022-10-28 2022-07-14\n",
       "7822        s13       p10     False 2022-10-29 2022-11-18 2022-07-14"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['point_idx'] == \"p10\"][[\"sample_idx\", \"point_idx\", \"har_evnt\", \"start_date\", \"end_date\", \"finHarvDat\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GeoDataFrame' object has no attribute 'har_event'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m np\u001b[39m.\u001b[39msum(df\u001b[39m.\u001b[39;49mhar_event)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/harvest-event-detec-Fyp2lGEN-py3.9/lib/python3.9/site-packages/pandas/core/generic.py:5902\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5895\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   5896\u001b[0m     name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal_names_set\n\u001b[1;32m   5897\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metadata\n\u001b[1;32m   5898\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accessors\n\u001b[1;32m   5899\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info_axis\u001b[39m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[1;32m   5900\u001b[0m ):\n\u001b[1;32m   5901\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[name]\n\u001b[0;32m-> 5902\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__getattribute__\u001b[39;49m(\u001b[39mself\u001b[39;49m, name)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GeoDataFrame' object has no attribute 'har_event'"
     ]
    }
   ],
   "source": [
    "np.sum(df.har_event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "harvest-event-detec-Fyp2lGEN-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
