{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-05 14:47:42.389825: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import geopandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO try only with best performing numeric columns for input into model first\n",
    "# TODO select features for deep learning model after ranking features with random forest (feature importance)\n",
    "# TODO lstm network\n",
    "# TODO SMOTE algorithm, for upsampling havested fields; we only have ~300 :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#local scripts\n",
    "from scripts import veg_indices, utilities, plots\n",
    "#from scripts.utilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cpied from learning_about-data.ipynb\n",
    "BANDS_DICT = {   'B2': 'Blue',\n",
    "            'B3': 'Green',\n",
    "            'B4': 'Red',\n",
    "            'B5': 'Red_Edge_1',\n",
    "            'B6': 'Red_Edge_2',\n",
    "            'B7': 'Red_Edge_3',\n",
    "            'B8': 'NIR',\n",
    "            'B8A': 'Red_Edge_4',\n",
    "            'B11': 'SWIR_1',\n",
    "            'B12': 'SWIR_2'}\n",
    "\n",
    "BANDS = list(BANDS_DICT.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cpied from learning_about-data.ipynb\n",
    "DF = geopandas.read_file('../data/merged_images.geojson')\n",
    "DF.rename(columns = {'is_within_period':'har_evnt'}, inplace = True)\n",
    "NUM_SAMPLES = len(np.unique(DF.image_idx)) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B11</th>\n",
       "      <th>B12</th>\n",
       "      <th>B2</th>\n",
       "      <th>B3</th>\n",
       "      <th>B4</th>\n",
       "      <th>B5</th>\n",
       "      <th>B6</th>\n",
       "      <th>B7</th>\n",
       "      <th>B8</th>\n",
       "      <th>B8A</th>\n",
       "      <th>NDVI</th>\n",
       "      <th>finHarvDat</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>point_idx</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>har_evnt</th>\n",
       "      <th>image_idx</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2022-08-11</td>\n",
       "      <td>50.655048</td>\n",
       "      <td>25.458684</td>\n",
       "      <td>p0</td>\n",
       "      <td>2022-01-08</td>\n",
       "      <td>2022-01-28</td>\n",
       "      <td>False</td>\n",
       "      <td>i0</td>\n",
       "      <td>POINT (25.45868 50.65505)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaT</td>\n",
       "      <td>50.294633</td>\n",
       "      <td>36.289471</td>\n",
       "      <td>p1</td>\n",
       "      <td>2022-01-08</td>\n",
       "      <td>2022-01-28</td>\n",
       "      <td>False</td>\n",
       "      <td>i0</td>\n",
       "      <td>POINT (36.28947 50.29463)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaT</td>\n",
       "      <td>50.860849</td>\n",
       "      <td>32.548484</td>\n",
       "      <td>p2</td>\n",
       "      <td>2022-01-08</td>\n",
       "      <td>2022-01-28</td>\n",
       "      <td>False</td>\n",
       "      <td>i0</td>\n",
       "      <td>POINT (32.54848 50.86085)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaT</td>\n",
       "      <td>50.928689</td>\n",
       "      <td>31.637558</td>\n",
       "      <td>p3</td>\n",
       "      <td>2022-01-08</td>\n",
       "      <td>2022-01-28</td>\n",
       "      <td>False</td>\n",
       "      <td>i0</td>\n",
       "      <td>POINT (31.63756 50.92869)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1424</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.0432</td>\n",
       "      <td>0.0631</td>\n",
       "      <td>0.07150</td>\n",
       "      <td>0.07760</td>\n",
       "      <td>0.08510</td>\n",
       "      <td>0.1066</td>\n",
       "      <td>0.1043</td>\n",
       "      <td>0.256335</td>\n",
       "      <td>2022-07-23</td>\n",
       "      <td>48.307964</td>\n",
       "      <td>37.348245</td>\n",
       "      <td>p4</td>\n",
       "      <td>2022-01-08</td>\n",
       "      <td>2022-01-28</td>\n",
       "      <td>False</td>\n",
       "      <td>i0</td>\n",
       "      <td>POINT (37.34824 48.30796)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9481</th>\n",
       "      <td>0.2557</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.0740</td>\n",
       "      <td>0.0973</td>\n",
       "      <td>0.11695</td>\n",
       "      <td>0.14255</td>\n",
       "      <td>0.15525</td>\n",
       "      <td>0.1920</td>\n",
       "      <td>0.1847</td>\n",
       "      <td>0.327342</td>\n",
       "      <td>NaT</td>\n",
       "      <td>49.723156</td>\n",
       "      <td>36.817274</td>\n",
       "      <td>p553</td>\n",
       "      <td>2022-12-10</td>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>False</td>\n",
       "      <td>i16</td>\n",
       "      <td>POINT (36.81727 49.72316)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9482</th>\n",
       "      <td>0.1616</td>\n",
       "      <td>0.1235</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.0442</td>\n",
       "      <td>0.0525</td>\n",
       "      <td>0.06390</td>\n",
       "      <td>0.08950</td>\n",
       "      <td>0.09310</td>\n",
       "      <td>0.1152</td>\n",
       "      <td>0.1073</td>\n",
       "      <td>0.373882</td>\n",
       "      <td>NaT</td>\n",
       "      <td>45.578351</td>\n",
       "      <td>28.700480</td>\n",
       "      <td>p554</td>\n",
       "      <td>2022-12-10</td>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>False</td>\n",
       "      <td>i16</td>\n",
       "      <td>POINT (28.70048 45.57835)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9483</th>\n",
       "      <td>0.1675</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.0678</td>\n",
       "      <td>0.0460</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.23980</td>\n",
       "      <td>0.26430</td>\n",
       "      <td>0.2832</td>\n",
       "      <td>0.2783</td>\n",
       "      <td>0.720535</td>\n",
       "      <td>NaT</td>\n",
       "      <td>46.693510</td>\n",
       "      <td>35.051003</td>\n",
       "      <td>p555</td>\n",
       "      <td>2022-12-10</td>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>False</td>\n",
       "      <td>i16</td>\n",
       "      <td>POINT (35.05100 46.69351)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9484</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2022-07-30</td>\n",
       "      <td>50.451929</td>\n",
       "      <td>33.668204</td>\n",
       "      <td>p556</td>\n",
       "      <td>2022-12-10</td>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>False</td>\n",
       "      <td>i16</td>\n",
       "      <td>POINT (33.66820 50.45193)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9485</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaT</td>\n",
       "      <td>46.994448</td>\n",
       "      <td>30.633461</td>\n",
       "      <td>p557</td>\n",
       "      <td>2022-12-10</td>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>False</td>\n",
       "      <td>i16</td>\n",
       "      <td>POINT (30.63346 46.99445)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9486 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         B11     B12     B2      B3      B4       B5       B6       B7  \\\n",
       "0     0.1000  0.1000  0.100  0.1000  0.1000  0.10000  0.10000  0.10000   \n",
       "1     0.1000  0.1000  0.100  0.1000  0.1000  0.10000  0.10000  0.10000   \n",
       "2     0.1000  0.1000  0.100  0.1000  0.1000  0.10000  0.10000  0.10000   \n",
       "3     0.1000  0.1000  0.100  0.1000  0.1000  0.10000  0.10000  0.10000   \n",
       "4     0.1424  0.1083  0.030  0.0432  0.0631  0.07150  0.07760  0.08510   \n",
       "...      ...     ...    ...     ...     ...      ...      ...      ...   \n",
       "9481  0.2557  0.1875  0.065  0.0740  0.0973  0.11695  0.14255  0.15525   \n",
       "9482  0.1616  0.1235  0.028  0.0442  0.0525  0.06390  0.08950  0.09310   \n",
       "9483  0.1675  0.1030  0.043  0.0678  0.0460  0.10960  0.23980  0.26430   \n",
       "9484  0.1000  0.1000  0.100  0.1000  0.1000  0.10000  0.10000  0.10000   \n",
       "9485  0.1000  0.1000  0.100  0.1000  0.1000  0.10000  0.10000  0.10000   \n",
       "\n",
       "          B8     B8A      NDVI finHarvDat        lat        lon point_idx  \\\n",
       "0     0.1000  0.1000  0.000000 2022-08-11  50.655048  25.458684        p0   \n",
       "1     0.1000  0.1000  0.000000        NaT  50.294633  36.289471        p1   \n",
       "2     0.1000  0.1000  0.000000        NaT  50.860849  32.548484        p2   \n",
       "3     0.1000  0.1000  0.000000        NaT  50.928689  31.637558        p3   \n",
       "4     0.1066  0.1043  0.256335 2022-07-23  48.307964  37.348245        p4   \n",
       "...      ...     ...       ...        ...        ...        ...       ...   \n",
       "9481  0.1920  0.1847  0.327342        NaT  49.723156  36.817274      p553   \n",
       "9482  0.1152  0.1073  0.373882        NaT  45.578351  28.700480      p554   \n",
       "9483  0.2832  0.2783  0.720535        NaT  46.693510  35.051003      p555   \n",
       "9484  0.1000  0.1000  0.000000 2022-07-30  50.451929  33.668204      p556   \n",
       "9485  0.1000  0.1000  0.000000        NaT  46.994448  30.633461      p557   \n",
       "\n",
       "     start_date   end_date  har_evnt image_idx                   geometry  \n",
       "0    2022-01-08 2022-01-28     False        i0  POINT (25.45868 50.65505)  \n",
       "1    2022-01-08 2022-01-28     False        i0  POINT (36.28947 50.29463)  \n",
       "2    2022-01-08 2022-01-28     False        i0  POINT (32.54848 50.86085)  \n",
       "3    2022-01-08 2022-01-28     False        i0  POINT (31.63756 50.92869)  \n",
       "4    2022-01-08 2022-01-28     False        i0  POINT (37.34824 48.30796)  \n",
       "...         ...        ...       ...       ...                        ...  \n",
       "9481 2022-12-10 2022-12-30     False       i16  POINT (36.81727 49.72316)  \n",
       "9482 2022-12-10 2022-12-30     False       i16  POINT (28.70048 45.57835)  \n",
       "9483 2022-12-10 2022-12-30     False       i16  POINT (35.05100 46.69351)  \n",
       "9484 2022-12-10 2022-12-30     False       i16  POINT (33.66820 50.45193)  \n",
       "9485 2022-12-10 2022-12-30     False       i16  POINT (30.63346 46.99445)  \n",
       "\n",
       "[9486 rows x 20 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added:  ['DVI', 'RVI', 'ARVI', 'PSSRa', 'NDI45', 'GNDVI', 'MCARI', 'IRECI', 'CIr', 'MTCI', 'NDVIre', 'NIRv', 'EVI', 'NDTI', 'NDMI', 'MSI', 'GCI', 'NBRI', 'BSI', 'NDWI', 'NDSI']\n",
      "Added:  ['sample_idx', 'DVI_diff', 'RVI_diff', 'ARVI_diff', 'PSSRa_diff', 'NDI45_diff', 'GNDVI_diff', 'MCARI_diff', 'IRECI_diff', 'CIr_diff', 'MTCI_diff', 'NDVIre_diff', 'NIRv_diff', 'EVI_diff', 'NDTI_diff', 'NDMI_diff', 'MSI_diff', 'GCI_diff', 'NBRI_diff', 'BSI_diff', 'NDWI_diff', 'NDSI_diff', 'NDVI_diff']\n",
      "Index(['B11', 'B12', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'NDVI',\n",
      "       'finHarvDat', 'lat', 'lon', 'point_idx', 'start_date', 'end_date',\n",
      "       'har_evnt', 'image_idx', 'geometry', 'DVI', 'RVI', 'ARVI', 'PSSRa',\n",
      "       'NDI45', 'GNDVI', 'MCARI', 'IRECI', 'CIr', 'MTCI', 'NDVIre', 'NIRv',\n",
      "       'EVI', 'NDTI', 'NDMI', 'MSI', 'GCI', 'NBRI', 'BSI', 'NDWI', 'NDSI',\n",
      "       'pt_idx', 'img_idx', 'DVI_diff', 'RVI_diff', 'ARVI_diff', 'PSSRa_diff',\n",
      "       'NDI45_diff', 'GNDVI_diff', 'MCARI_diff', 'IRECI_diff', 'CIr_diff',\n",
      "       'MTCI_diff', 'NDVIre_diff', 'NIRv_diff', 'EVI_diff', 'NDTI_diff',\n",
      "       'NDMI_diff', 'MSI_diff', 'GCI_diff', 'NBRI_diff', 'BSI_diff',\n",
      "       'NDWI_diff', 'NDSI_diff', 'NDVI_diff', 'sample_idx'],\n",
      "      dtype='object') (6678, 66)\n"
     ]
    }
   ],
   "source": [
    "# cpied from learning_about-data.ipynb\n",
    "df = DF.copy()\n",
    "df = df[(df.NDVI) != 0] # drop invalid points\n",
    "VEG_INDICES_NAMES = veg_indices.add_veg_indices(df) + ['NDVI'] \n",
    "VEG_DIFF_NAMES = veg_indices.add_veg_diff(df, VEG_INDICES_NAMES)\n",
    "NUMERIC_COLS = BANDS + VEG_INDICES_NAMES + VEG_DIFF_NAMES\n",
    "df = df.dropna(subset=['sample_idx']) # removes the first image, because sample_idx is NaN there\n",
    "\n",
    "\n",
    "\"\"\" \n",
    "# only look at samples 6, 7, 8, 9\n",
    "new_df = None\n",
    "for i in range(6, 9 + 1):\n",
    "\n",
    "    curr_df = df[df[\"sample_idx\"] == f\"s{i}\"]\n",
    "    if(type(new_df) == type(None)):\n",
    "        new_df = curr_df\n",
    "    else:\n",
    "        new_df = pd.concat([new_df, curr_df])\n",
    "df = new_df\n",
    "\"\"\"\n",
    "\n",
    "print(df.columns, df.shape)\n",
    "\n",
    "\n",
    "# For each 3-week image, standarize each column\n",
    "df = utilities.get_rm_outlier_standarize(df, NUMERIC_COLS, rm_outliers=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upsample harvevnt == true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(328, 66)\n",
      "(6350, 66)\n"
     ]
    }
   ],
   "source": [
    "har_evnt_true_df = df[df[\"har_evnt\"]]\n",
    "har_evnt_false_df = df[df[\"har_evnt\"] == False]\n",
    "print(har_evnt_true_df.shape)\n",
    "print(har_evnt_false_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6350, 66)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "upsampled_har_evnt_true_df = resample(har_evnt_true_df, n_samples=har_evnt_false_df.shape[0],\n",
    "                                                 replace=True, random_state=42)\n",
    "upsampled_har_evnt_true_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12700, 66)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([upsampled_har_evnt_true_df, har_evnt_false_df])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_hot(df:pd.DataFrame, colName: str, retArrays=False):\n",
    "    lookupTable, indexed_dataSet = np.unique(df[colName], return_inverse=True)\n",
    "    tpls = tf.keras.utils.to_categorical(indexed_dataSet)\n",
    "\n",
    "    arrays = tpls.T[1:] # remove one column (not needed)\n",
    "    arrays = arrays.astype(np.float32) # tensorflow does not support bools, so float 32 is the best we can do :/\n",
    "    if(retArrays):\n",
    "        return arrays\n",
    "\n",
    "    return arrays.T # return to n by m (n tuples of size m)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B11</th>\n",
       "      <th>B12</th>\n",
       "      <th>B2</th>\n",
       "      <th>B3</th>\n",
       "      <th>B4</th>\n",
       "      <th>B5</th>\n",
       "      <th>B6</th>\n",
       "      <th>B7</th>\n",
       "      <th>B8</th>\n",
       "      <th>B8A</th>\n",
       "      <th>...</th>\n",
       "      <th>NDTI_diff</th>\n",
       "      <th>NDMI_diff</th>\n",
       "      <th>MSI_diff</th>\n",
       "      <th>GCI_diff</th>\n",
       "      <th>NBRI_diff</th>\n",
       "      <th>BSI_diff</th>\n",
       "      <th>NDWI_diff</th>\n",
       "      <th>NDSI_diff</th>\n",
       "      <th>NDVI_diff</th>\n",
       "      <th>sample_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4839</th>\n",
       "      <td>1.385954</td>\n",
       "      <td>1.774244</td>\n",
       "      <td>0.129085</td>\n",
       "      <td>0.163238</td>\n",
       "      <td>0.334403</td>\n",
       "      <td>0.201913</td>\n",
       "      <td>-0.340219</td>\n",
       "      <td>-0.490786</td>\n",
       "      <td>-0.587137</td>\n",
       "      <td>-0.512474</td>\n",
       "      <td>...</td>\n",
       "      <td>0.286452</td>\n",
       "      <td>-1.452412</td>\n",
       "      <td>2.032427</td>\n",
       "      <td>-1.192398</td>\n",
       "      <td>0.591848</td>\n",
       "      <td>1.646797</td>\n",
       "      <td>-0.517996</td>\n",
       "      <td>-1.819393</td>\n",
       "      <td>-0.534278</td>\n",
       "      <td>s7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5507</th>\n",
       "      <td>1.060614</td>\n",
       "      <td>0.635746</td>\n",
       "      <td>0.440772</td>\n",
       "      <td>0.356287</td>\n",
       "      <td>0.354920</td>\n",
       "      <td>0.597320</td>\n",
       "      <td>0.689155</td>\n",
       "      <td>0.765114</td>\n",
       "      <td>0.516060</td>\n",
       "      <td>0.858730</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.054707</td>\n",
       "      <td>-0.758196</td>\n",
       "      <td>0.209549</td>\n",
       "      <td>-0.362585</td>\n",
       "      <td>0.447302</td>\n",
       "      <td>0.036857</td>\n",
       "      <td>0.310800</td>\n",
       "      <td>-0.319903</td>\n",
       "      <td>-0.133213</td>\n",
       "      <td>s8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4848</th>\n",
       "      <td>-0.187346</td>\n",
       "      <td>-0.245464</td>\n",
       "      <td>-0.103838</td>\n",
       "      <td>-0.059468</td>\n",
       "      <td>0.278830</td>\n",
       "      <td>0.111869</td>\n",
       "      <td>-0.316513</td>\n",
       "      <td>-0.288947</td>\n",
       "      <td>-0.212522</td>\n",
       "      <td>-0.256863</td>\n",
       "      <td>...</td>\n",
       "      <td>0.761207</td>\n",
       "      <td>-0.109927</td>\n",
       "      <td>-0.069356</td>\n",
       "      <td>-0.228613</td>\n",
       "      <td>0.368772</td>\n",
       "      <td>0.118269</td>\n",
       "      <td>-0.266088</td>\n",
       "      <td>0.002666</td>\n",
       "      <td>-0.603419</td>\n",
       "      <td>s7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4728</th>\n",
       "      <td>-0.153022</td>\n",
       "      <td>-0.029013</td>\n",
       "      <td>-0.250125</td>\n",
       "      <td>-0.332513</td>\n",
       "      <td>-0.246332</td>\n",
       "      <td>-0.474782</td>\n",
       "      <td>-0.943350</td>\n",
       "      <td>-1.027254</td>\n",
       "      <td>-1.050201</td>\n",
       "      <td>-1.103574</td>\n",
       "      <td>...</td>\n",
       "      <td>0.701232</td>\n",
       "      <td>-1.304036</td>\n",
       "      <td>1.226621</td>\n",
       "      <td>-0.758460</td>\n",
       "      <td>0.446447</td>\n",
       "      <td>1.022054</td>\n",
       "      <td>-0.664009</td>\n",
       "      <td>-1.163051</td>\n",
       "      <td>-0.292966</td>\n",
       "      <td>s7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5196</th>\n",
       "      <td>-0.643317</td>\n",
       "      <td>-0.868245</td>\n",
       "      <td>-0.232785</td>\n",
       "      <td>-0.251894</td>\n",
       "      <td>-0.187857</td>\n",
       "      <td>-0.274461</td>\n",
       "      <td>-0.413436</td>\n",
       "      <td>-0.359850</td>\n",
       "      <td>-0.393159</td>\n",
       "      <td>-0.371695</td>\n",
       "      <td>...</td>\n",
       "      <td>1.163120</td>\n",
       "      <td>-0.398016</td>\n",
       "      <td>-0.345067</td>\n",
       "      <td>-0.013404</td>\n",
       "      <td>0.395945</td>\n",
       "      <td>-0.380607</td>\n",
       "      <td>0.075882</td>\n",
       "      <td>0.267730</td>\n",
       "      <td>-0.348433</td>\n",
       "      <td>s8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9475</th>\n",
       "      <td>3.322104</td>\n",
       "      <td>2.328019</td>\n",
       "      <td>0.132010</td>\n",
       "      <td>0.231196</td>\n",
       "      <td>0.095625</td>\n",
       "      <td>0.472431</td>\n",
       "      <td>1.725177</td>\n",
       "      <td>2.015223</td>\n",
       "      <td>2.066392</td>\n",
       "      <td>2.180961</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.826355</td>\n",
       "      <td>0.732779</td>\n",
       "      <td>-1.169280</td>\n",
       "      <td>1.612652</td>\n",
       "      <td>-0.915200</td>\n",
       "      <td>-1.344209</td>\n",
       "      <td>0.282752</td>\n",
       "      <td>0.795201</td>\n",
       "      <td>0.566191</td>\n",
       "      <td>s15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9478</th>\n",
       "      <td>-1.628924</td>\n",
       "      <td>-1.062433</td>\n",
       "      <td>3.578395</td>\n",
       "      <td>3.457746</td>\n",
       "      <td>3.404489</td>\n",
       "      <td>3.259756</td>\n",
       "      <td>3.083942</td>\n",
       "      <td>2.963168</td>\n",
       "      <td>3.031307</td>\n",
       "      <td>2.897218</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.668641</td>\n",
       "      <td>2.848363</td>\n",
       "      <td>-2.258848</td>\n",
       "      <td>-0.110247</td>\n",
       "      <td>1.915134</td>\n",
       "      <td>-2.202332</td>\n",
       "      <td>2.572595</td>\n",
       "      <td>2.716314</td>\n",
       "      <td>-2.818478</td>\n",
       "      <td>s15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9481</th>\n",
       "      <td>1.843392</td>\n",
       "      <td>1.368079</td>\n",
       "      <td>-0.275171</td>\n",
       "      <td>-0.257938</td>\n",
       "      <td>-0.181384</td>\n",
       "      <td>-0.168046</td>\n",
       "      <td>-0.179112</td>\n",
       "      <td>-0.158634</td>\n",
       "      <td>-0.057645</td>\n",
       "      <td>-0.060312</td>\n",
       "      <td>...</td>\n",
       "      <td>0.114312</td>\n",
       "      <td>-0.434865</td>\n",
       "      <td>0.208224</td>\n",
       "      <td>0.134505</td>\n",
       "      <td>-0.290227</td>\n",
       "      <td>0.266190</td>\n",
       "      <td>-0.606048</td>\n",
       "      <td>-0.316902</td>\n",
       "      <td>0.445377</td>\n",
       "      <td>s15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9482</th>\n",
       "      <td>-0.009429</td>\n",
       "      <td>-0.141409</td>\n",
       "      <td>-0.468817</td>\n",
       "      <td>-0.419537</td>\n",
       "      <td>-0.416868</td>\n",
       "      <td>-0.447121</td>\n",
       "      <td>-0.460629</td>\n",
       "      <td>-0.493758</td>\n",
       "      <td>-0.450153</td>\n",
       "      <td>-0.492917</td>\n",
       "      <td>...</td>\n",
       "      <td>0.411511</td>\n",
       "      <td>-0.449486</td>\n",
       "      <td>0.316610</td>\n",
       "      <td>0.088229</td>\n",
       "      <td>-0.345191</td>\n",
       "      <td>0.438725</td>\n",
       "      <td>-0.761268</td>\n",
       "      <td>-0.373365</td>\n",
       "      <td>0.573503</td>\n",
       "      <td>s15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9483</th>\n",
       "      <td>0.106742</td>\n",
       "      <td>-0.624917</td>\n",
       "      <td>-0.390312</td>\n",
       "      <td>-0.291560</td>\n",
       "      <td>-0.451034</td>\n",
       "      <td>-0.206712</td>\n",
       "      <td>0.336959</td>\n",
       "      <td>0.429383</td>\n",
       "      <td>0.408457</td>\n",
       "      <td>0.462838</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.675552</td>\n",
       "      <td>0.465889</td>\n",
       "      <td>-1.073355</td>\n",
       "      <td>1.948092</td>\n",
       "      <td>-1.352097</td>\n",
       "      <td>-1.349143</td>\n",
       "      <td>0.104137</td>\n",
       "      <td>0.640749</td>\n",
       "      <td>0.962237</td>\n",
       "      <td>s15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12700 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           B11       B12        B2        B3        B4        B5        B6  \\\n",
       "4839  1.385954  1.774244  0.129085  0.163238  0.334403  0.201913 -0.340219   \n",
       "5507  1.060614  0.635746  0.440772  0.356287  0.354920  0.597320  0.689155   \n",
       "4848 -0.187346 -0.245464 -0.103838 -0.059468  0.278830  0.111869 -0.316513   \n",
       "4728 -0.153022 -0.029013 -0.250125 -0.332513 -0.246332 -0.474782 -0.943350   \n",
       "5196 -0.643317 -0.868245 -0.232785 -0.251894 -0.187857 -0.274461 -0.413436   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "9475  3.322104  2.328019  0.132010  0.231196  0.095625  0.472431  1.725177   \n",
       "9478 -1.628924 -1.062433  3.578395  3.457746  3.404489  3.259756  3.083942   \n",
       "9481  1.843392  1.368079 -0.275171 -0.257938 -0.181384 -0.168046 -0.179112   \n",
       "9482 -0.009429 -0.141409 -0.468817 -0.419537 -0.416868 -0.447121 -0.460629   \n",
       "9483  0.106742 -0.624917 -0.390312 -0.291560 -0.451034 -0.206712  0.336959   \n",
       "\n",
       "            B7        B8       B8A  ...  NDTI_diff NDMI_diff  MSI_diff  \\\n",
       "4839 -0.490786 -0.587137 -0.512474  ...   0.286452 -1.452412  2.032427   \n",
       "5507  0.765114  0.516060  0.858730  ...  -0.054707 -0.758196  0.209549   \n",
       "4848 -0.288947 -0.212522 -0.256863  ...   0.761207 -0.109927 -0.069356   \n",
       "4728 -1.027254 -1.050201 -1.103574  ...   0.701232 -1.304036  1.226621   \n",
       "5196 -0.359850 -0.393159 -0.371695  ...   1.163120 -0.398016 -0.345067   \n",
       "...        ...       ...       ...  ...        ...       ...       ...   \n",
       "9475  2.015223  2.066392  2.180961  ...  -4.826355  0.732779 -1.169280   \n",
       "9478  2.963168  3.031307  2.897218  ...  -0.668641  2.848363 -2.258848   \n",
       "9481 -0.158634 -0.057645 -0.060312  ...   0.114312 -0.434865  0.208224   \n",
       "9482 -0.493758 -0.450153 -0.492917  ...   0.411511 -0.449486  0.316610   \n",
       "9483  0.429383  0.408457  0.462838  ...  -1.675552  0.465889 -1.073355   \n",
       "\n",
       "      GCI_diff NBRI_diff  BSI_diff NDWI_diff  NDSI_diff NDVI_diff sample_idx  \n",
       "4839 -1.192398  0.591848  1.646797 -0.517996  -1.819393 -0.534278         s7  \n",
       "5507 -0.362585  0.447302  0.036857  0.310800  -0.319903 -0.133213         s8  \n",
       "4848 -0.228613  0.368772  0.118269 -0.266088   0.002666 -0.603419         s7  \n",
       "4728 -0.758460  0.446447  1.022054 -0.664009  -1.163051 -0.292966         s7  \n",
       "5196 -0.013404  0.395945 -0.380607  0.075882   0.267730 -0.348433         s8  \n",
       "...        ...       ...       ...       ...        ...       ...        ...  \n",
       "9475  1.612652 -0.915200 -1.344209  0.282752   0.795201  0.566191        s15  \n",
       "9478 -0.110247  1.915134 -2.202332  2.572595   2.716314 -2.818478        s15  \n",
       "9481  0.134505 -0.290227  0.266190 -0.606048  -0.316902  0.445377        s15  \n",
       "9482  0.088229 -0.345191  0.438725 -0.761268  -0.373365  0.573503        s15  \n",
       "9483  1.948092 -1.352097 -1.349143  0.104137   0.640749  0.962237        s15  \n",
       "\n",
       "[12700 rows x 66 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = df[VEG_DIFF_NAMES]\n",
    "df_X = df_X.drop(['DVI_diff'], axis=1) # drop nana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_X.to_numpy().reshape((df_X.shape[0], df_X.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df[\"har_evnt\"].to_numpy().astype(np.float32)\n",
    "#df_Y = df_Y.reshape((df_Y.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12700, 21, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.16120678],\n",
       "        [ 0.5186668 ],\n",
       "        [-0.66685818],\n",
       "        ...,\n",
       "        [-0.51799586],\n",
       "        [-1.81939281],\n",
       "        [-0.53427836]],\n",
       "\n",
       "       [[-0.02536285],\n",
       "        [-1.07951348],\n",
       "        [ 0.09868929],\n",
       "        ...,\n",
       "        [ 0.31080032],\n",
       "        [-0.31990275],\n",
       "        [-0.13321314]],\n",
       "\n",
       "       [[ 0.59012555],\n",
       "        [ 1.21949278],\n",
       "        [-0.62796458],\n",
       "        ...,\n",
       "        [-0.26608761],\n",
       "        [ 0.00266588],\n",
       "        [-0.60341929]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-0.36984042],\n",
       "        [ 0.48810307],\n",
       "        [-0.29588152],\n",
       "        ...,\n",
       "        [-0.60604802],\n",
       "        [-0.31690166],\n",
       "        [ 0.44537728]],\n",
       "\n",
       "       [[-0.43992693],\n",
       "        [ 0.97390859],\n",
       "        [-0.26861977],\n",
       "        ...,\n",
       "        [-0.76126849],\n",
       "        [-0.37336542],\n",
       "        [ 0.57350275]],\n",
       "\n",
       "       [[-2.16175383],\n",
       "        [ 0.38730427],\n",
       "        [ 2.64524903],\n",
       "        ...,\n",
       "        [ 0.10413741],\n",
       "        [ 0.64074903],\n",
       "        [ 0.96223682]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_to_1hot(categorical_col_name:str):\n",
    "    names = []\n",
    "    arrays = get_one_hot(df, categorical_col_name, retArrays=True)\n",
    "    for i in range(len(arrays)):\n",
    "        arr = arrays[i]\n",
    "        name = f'{categorical_col_name}_1hot_{i}'\n",
    "        df[name] = arr\n",
    "        names.append(name)\n",
    "    return names\n",
    "    \"\"\"\n",
    "one_hot_names_X = convert_to_1hot(\"sample_idx\")\n",
    "one_hot_names_Y = convert_to_1hot(\"har_evnt\")\n",
    "\n",
    "print(df.columns)\n",
    "print(one_hot_names_X)\n",
    "print(one_hot_names_Y)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12700, 21, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[1], X.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-05 15:04:16.952994: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dropout, BatchNormalization\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(X.shape[1],X.shape[2])),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Flatten(),\n",
    "    BatchNormalization(),\n",
    "    Dense(units=64, activation='relu'),\n",
    "    Dense(units=32, activation='relu'),\n",
    "    Dense(units=8, activation='relu'),\n",
    "    Dense(units=1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "#model.compile(optimizer='adam', loss='mse', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 19, 32)            128       \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 9, 32)            0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 288)               0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 288)              1152      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                18496     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 8)                 264       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,129\n",
      "Trainable params: 21,553\n",
      "Non-trainable params: 576\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "318/318 [==============================] - 4s 5ms/step - loss: 0.4407 - binary_accuracy: 0.8060 - val_loss: 0.5979 - val_binary_accuracy: 0.6543\n",
      "Epoch 2/30\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 0.3223 - binary_accuracy: 0.8774 - val_loss: 1.1588 - val_binary_accuracy: 0.4197\n",
      "Epoch 3/30\n",
      "318/318 [==============================] - 2s 5ms/step - loss: 0.2791 - binary_accuracy: 0.9004 - val_loss: 1.5026 - val_binary_accuracy: 0.3476\n",
      "Epoch 4/30\n",
      "318/318 [==============================] - 1s 5ms/step - loss: 0.2601 - binary_accuracy: 0.9025 - val_loss: 1.4092 - val_binary_accuracy: 0.4205\n",
      "Epoch 5/30\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 0.2410 - binary_accuracy: 0.9146 - val_loss: 1.1710 - val_binary_accuracy: 0.4535\n",
      "Epoch 6/30\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 0.2253 - binary_accuracy: 0.9196 - val_loss: 1.0650 - val_binary_accuracy: 0.5185\n",
      "Epoch 7/30\n",
      "318/318 [==============================] - 1s 4ms/step - loss: 0.2142 - binary_accuracy: 0.9228 - val_loss: 1.3713 - val_binary_accuracy: 0.4697\n",
      "Epoch 8/30\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 0.2033 - binary_accuracy: 0.9268 - val_loss: 1.0259 - val_binary_accuracy: 0.5516\n",
      "Epoch 9/30\n",
      "318/318 [==============================] - 1s 4ms/step - loss: 0.1946 - binary_accuracy: 0.9331 - val_loss: 1.3709 - val_binary_accuracy: 0.4484\n",
      "Epoch 10/30\n",
      "318/318 [==============================] - 1s 4ms/step - loss: 0.1896 - binary_accuracy: 0.9337 - val_loss: 1.3648 - val_binary_accuracy: 0.4429\n",
      "Epoch 11/30\n",
      "318/318 [==============================] - 1s 4ms/step - loss: 0.1845 - binary_accuracy: 0.9349 - val_loss: 0.9336 - val_binary_accuracy: 0.6063\n",
      "Epoch 12/30\n",
      "318/318 [==============================] - 1s 4ms/step - loss: 0.1799 - binary_accuracy: 0.9386 - val_loss: 1.1895 - val_binary_accuracy: 0.5335\n",
      "Epoch 13/30\n",
      "318/318 [==============================] - 1s 4ms/step - loss: 0.1743 - binary_accuracy: 0.9406 - val_loss: 1.0365 - val_binary_accuracy: 0.5780\n",
      "Epoch 14/30\n",
      "318/318 [==============================] - 1s 4ms/step - loss: 0.1693 - binary_accuracy: 0.9407 - val_loss: 1.2863 - val_binary_accuracy: 0.5240\n",
      "Epoch 15/30\n",
      "318/318 [==============================] - 2s 5ms/step - loss: 0.1662 - binary_accuracy: 0.9424 - val_loss: 0.8920 - val_binary_accuracy: 0.6618\n",
      "Epoch 16/30\n",
      "318/318 [==============================] - 1s 4ms/step - loss: 0.1647 - binary_accuracy: 0.9427 - val_loss: 1.4422 - val_binary_accuracy: 0.4630\n",
      "Epoch 17/30\n",
      "318/318 [==============================] - 3s 9ms/step - loss: 0.1507 - binary_accuracy: 0.9473 - val_loss: 1.1054 - val_binary_accuracy: 0.5736\n",
      "Epoch 18/30\n",
      "318/318 [==============================] - 4s 11ms/step - loss: 0.1459 - binary_accuracy: 0.9490 - val_loss: 1.3839 - val_binary_accuracy: 0.5272\n",
      "Epoch 19/30\n",
      "318/318 [==============================] - 3s 10ms/step - loss: 0.1495 - binary_accuracy: 0.9498 - val_loss: 1.4392 - val_binary_accuracy: 0.5327\n",
      "Epoch 20/30\n",
      "318/318 [==============================] - 3s 8ms/step - loss: 0.1422 - binary_accuracy: 0.9526 - val_loss: 1.2857 - val_binary_accuracy: 0.5622\n",
      "Epoch 21/30\n",
      "318/318 [==============================] - 3s 9ms/step - loss: 0.1419 - binary_accuracy: 0.9522 - val_loss: 1.0582 - val_binary_accuracy: 0.5976\n",
      "Epoch 22/30\n",
      "318/318 [==============================] - 4s 12ms/step - loss: 0.1330 - binary_accuracy: 0.9563 - val_loss: 1.4466 - val_binary_accuracy: 0.5335\n",
      "Epoch 23/30\n",
      "318/318 [==============================] - 4s 13ms/step - loss: 0.1415 - binary_accuracy: 0.9515 - val_loss: 1.1792 - val_binary_accuracy: 0.5799\n",
      "Epoch 24/30\n",
      "318/318 [==============================] - 3s 10ms/step - loss: 0.1392 - binary_accuracy: 0.9546 - val_loss: 1.3938 - val_binary_accuracy: 0.5575\n",
      "Epoch 25/30\n",
      "318/318 [==============================] - 3s 8ms/step - loss: 0.1326 - binary_accuracy: 0.9550 - val_loss: 1.5354 - val_binary_accuracy: 0.5098\n",
      "Epoch 26/30\n",
      "318/318 [==============================] - 2s 5ms/step - loss: 0.1321 - binary_accuracy: 0.9540 - val_loss: 1.5087 - val_binary_accuracy: 0.5138\n",
      "Epoch 27/30\n",
      "318/318 [==============================] - 1s 4ms/step - loss: 0.1301 - binary_accuracy: 0.9562 - val_loss: 1.1208 - val_binary_accuracy: 0.6083\n",
      "Epoch 28/30\n",
      "318/318 [==============================] - 1s 4ms/step - loss: 0.1229 - binary_accuracy: 0.9582 - val_loss: 1.3277 - val_binary_accuracy: 0.5681\n",
      "Epoch 29/30\n",
      "318/318 [==============================] - 2s 5ms/step - loss: 0.1233 - binary_accuracy: 0.9584 - val_loss: 0.9143 - val_binary_accuracy: 0.6933\n",
      "Epoch 30/30\n",
      "318/318 [==============================] - 1s 4ms/step - loss: 0.1219 - binary_accuracy: 0.9576 - val_loss: 1.4329 - val_binary_accuracy: 0.5654\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f98c9bf9670>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y, epochs=30, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.        ,  0.        ,  0.        , ...,  0.00552828,\n",
       "         -0.00659141, -0.00677609],\n",
       "        [ 0.00757559,  0.        ,  0.        , ..., -0.00238965,\n",
       "         -0.01646883, -0.01451381],\n",
       "        [ 0.        ,  0.00757559,  0.        , ..., -0.00472415,\n",
       "         -0.00212759, -0.00230309],\n",
       "        [ 0.        ,  0.        ,  0.00757559, ...,  0.00232412,\n",
       "          0.00348978,  0.00299009]],\n",
       "\n",
       "       [[ 0.        ,  0.        ,  0.        , ...,  0.00921513,\n",
       "          0.00537546,  0.00040839],\n",
       "        [ 0.00757559,  0.        ,  0.        , ...,  0.0002729 ,\n",
       "          0.00560671,  0.00508392],\n",
       "        [ 0.        ,  0.00757559,  0.        , ..., -0.00203002,\n",
       "          0.00129858,  0.00159386],\n",
       "        [ 0.        ,  0.        ,  0.00757559, ...,  0.01397219,\n",
       "         -0.00468563, -0.00910651]],\n",
       "\n",
       "       [[ 0.        ,  0.        ,  0.        , ...,  0.01151   ,\n",
       "         -0.00425536, -0.00547394],\n",
       "        [ 0.00757559,  0.        ,  0.        , ...,  0.00533579,\n",
       "         -0.00712918, -0.00816971],\n",
       "        [ 0.        ,  0.00757559,  0.        , ...,  0.00495386,\n",
       "          0.00266738,  0.00054649],\n",
       "        [ 0.        ,  0.        ,  0.00757559, ..., -0.00891716,\n",
       "          0.00700444,  0.01336099]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.        ,  0.        ,  0.        , ..., -0.00381007,\n",
       "          0.00246621,  0.00270697],\n",
       "        [ 0.00757559,  0.        ,  0.        , ...,  0.00583502,\n",
       "          0.01261146,  0.01024062],\n",
       "        [ 0.        ,  0.00757559,  0.        , ..., -0.00509299,\n",
       "          0.00385369,  0.00856684],\n",
       "        [ 0.        ,  0.        ,  0.00757559, ..., -0.00514639,\n",
       "          0.00443211,  0.00754019]],\n",
       "\n",
       "       [[ 0.        ,  0.        ,  0.        , ...,  0.04468748,\n",
       "          0.01935934,  0.00836849],\n",
       "        [ 0.00757559,  0.        ,  0.        , ...,  0.00039393,\n",
       "         -0.00369049, -0.00365194],\n",
       "        [ 0.        ,  0.00757559,  0.        , ..., -0.00803568,\n",
       "         -0.00708019, -0.00604907],\n",
       "        [ 0.        ,  0.        ,  0.00757559, ..., -0.00954347,\n",
       "          0.00319689,  0.00835033]],\n",
       "\n",
       "       [[ 0.        ,  0.        ,  0.        , ..., -0.00156536,\n",
       "          0.00570532,  0.00485835],\n",
       "        [ 0.00757559,  0.        ,  0.        , ...,  0.00376246,\n",
       "          0.00060788, -0.00155986],\n",
       "        [ 0.        ,  0.00757559,  0.        , ...,  0.00155012,\n",
       "         -0.00316042, -0.0020672 ],\n",
       "        [ 0.        ,  0.        ,  0.00757559, ..., -0.00264761,\n",
       "         -0.00460923, -0.00221478]]])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant(X)\n",
    "tf.math.l2_normalize(a).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/tahaalnufaili/Library/Caches/pypoetry/virtualenvs/harvest-event-detec-Fyp2lGEN-py3.9/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/tahaalnufaili/Library/Caches/pypoetry/virtualenvs/harvest-event-detec-Fyp2lGEN-py3.9/lib/python3.9/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/tahaalnufaili/Library/Caches/pypoetry/virtualenvs/harvest-event-detec-Fyp2lGEN-py3.9/lib/python3.9/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/tahaalnufaili/Library/Caches/pypoetry/virtualenvs/harvest-event-detec-Fyp2lGEN-py3.9/lib/python3.9/site-packages/keras/engine/training.py\", line 1023, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/tahaalnufaili/Library/Caches/pypoetry/virtualenvs/harvest-event-detec-Fyp2lGEN-py3.9/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/tahaalnufaili/Library/Caches/pypoetry/virtualenvs/harvest-event-detec-Fyp2lGEN-py3.9/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_3\" is incompatible with the layer: expected shape=(None, 1249, 57), found shape=(None, 57)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[75], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split\n\u001b[1;32m      3\u001b[0m trainX, testX, trainy, testy \u001b[39m=\u001b[39m  train_test_split(X, Y, test_size \u001b[39m=\u001b[39m \u001b[39m0.4\u001b[39m,random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m) \n\u001b[0;32m----> 5\u001b[0m evaluate_model(trainX, trainy, testX, testy)\n",
      "Cell \u001b[0;32mIn[71], line 14\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(trainX, trainy, testX, testy)\u001b[0m\n\u001b[1;32m     12\u001b[0m model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m, optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     13\u001b[0m \u001b[39m# fit network\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m model\u001b[39m.\u001b[39;49mfit(trainX, trainy, epochs\u001b[39m=\u001b[39;49mepochs, batch_size\u001b[39m=\u001b[39;49mbatch_size, verbose\u001b[39m=\u001b[39;49mverbose)\n\u001b[1;32m     15\u001b[0m \u001b[39m# evaluate model\u001b[39;00m\n\u001b[1;32m     16\u001b[0m _, accuracy \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(testX, testy, batch_size\u001b[39m=\u001b[39mbatch_size, verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/harvest-event-detec-Fyp2lGEN-py3.9/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/6q/tw4w22c97c98vxdk2crxzdb00000gn/T/__autograph_generated_fileemzwtj1w.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/tahaalnufaili/Library/Caches/pypoetry/virtualenvs/harvest-event-detec-Fyp2lGEN-py3.9/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/tahaalnufaili/Library/Caches/pypoetry/virtualenvs/harvest-event-detec-Fyp2lGEN-py3.9/lib/python3.9/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/tahaalnufaili/Library/Caches/pypoetry/virtualenvs/harvest-event-detec-Fyp2lGEN-py3.9/lib/python3.9/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/tahaalnufaili/Library/Caches/pypoetry/virtualenvs/harvest-event-detec-Fyp2lGEN-py3.9/lib/python3.9/site-packages/keras/engine/training.py\", line 1023, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/tahaalnufaili/Library/Caches/pypoetry/virtualenvs/harvest-event-detec-Fyp2lGEN-py3.9/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/tahaalnufaili/Library/Caches/pypoetry/virtualenvs/harvest-event-detec-Fyp2lGEN-py3.9/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_3\" is incompatible with the layer: expected shape=(None, 1249, 57), found shape=(None, 57)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "trainX, testX, trainy, testy =  train_test_split(X, Y, test_size = 0.4,random_state=42) \n",
    "\n",
    "evaluate_model(trainX, trainy, testX, testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1249, 1), (834, 57))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testX.shape, trainy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "harvest-event-detec-Fyp2lGEN-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
