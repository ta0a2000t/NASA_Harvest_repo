{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import google.auth\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import folium\n",
    "import time\n",
    "import geopandas\n",
    "import pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is needed to Successfully save authorization token. from ee.Authenticate()\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>To authorize access needed by Earth Engine, open the following\n",
       "        URL in a web browser and follow the instructions:</p>\n",
       "        <p><a href=https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=9fGUDkMvyczNjE8evDA0OvjjaMWwXSAqhylxvRMB5Ts&tc=m9BKIEpWW5kbGJwVUTdsBcSfjWty7TxX0C0GyhpR49g&cc=9fSRIrUkfsC6Lc9i7tSDEEIW9L3xyTsD3Uhr_JgFJOs>https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=9fGUDkMvyczNjE8evDA0OvjjaMWwXSAqhylxvRMB5Ts&tc=m9BKIEpWW5kbGJwVUTdsBcSfjWty7TxX0C0GyhpR49g&cc=9fSRIrUkfsC6Lc9i7tSDEEIW9L3xyTsD3Uhr_JgFJOs</a></p>\n",
       "        <p>The authorization workflow will generate a code, which you should paste in the box below.</p>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully saved authorization token.\n"
     ]
    }
   ],
   "source": [
    "ee.Authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bands used for prediction\n",
    "BANDS = ['B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B11', 'B12'] # bands with <= 30 resolution\n",
    "\n",
    "COUNTRY_GEOMETRY = ee.FeatureCollection(\"USDOS/LSIB_SIMPLE/2017\").filter(ee.Filter.eq('country_na', 'Ukraine'))\n",
    "COUNTRY_LATLON = 50., 31 # coordinate of center of ukraine"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Labeled Shape File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fid</th>\n",
       "      <th>cat</th>\n",
       "      <th>id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>strata</th>\n",
       "      <th>set</th>\n",
       "      <th>rd_id</th>\n",
       "      <th>lab_set1</th>\n",
       "      <th>val_set1</th>\n",
       "      <th>com_set1</th>\n",
       "      <th>lab_set2</th>\n",
       "      <th>val_set2</th>\n",
       "      <th>com_set2</th>\n",
       "      <th>finHarvDat</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>249.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>-321360.0</td>\n",
       "      <td>639156.0</td>\n",
       "      <td>50.655048</td>\n",
       "      <td>25.458684</td>\n",
       "      <td>20.0</td>\n",
       "      <td>free_ukraine</td>\n",
       "      <td>51.0</td>\n",
       "      <td>Shabri</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Harvested 11/08/22</td>\n",
       "      <td>Josef</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Harvested 05/08-11/08/22</td>\n",
       "      <td>11/08/22</td>\n",
       "      <td>POINT (2834056.683 6560486.924)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>165.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>447948.0</td>\n",
       "      <td>607452.0</td>\n",
       "      <td>50.294633</td>\n",
       "      <td>36.289471</td>\n",
       "      <td>20.0</td>\n",
       "      <td>free_ukraine</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Shabri</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Spring</td>\n",
       "      <td>Josef</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (4039734.283 6497444.336)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>400.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>399.0</td>\n",
       "      <td>179688.0</td>\n",
       "      <td>655860.0</td>\n",
       "      <td>50.860849</td>\n",
       "      <td>32.548484</td>\n",
       "      <td>20.0</td>\n",
       "      <td>free_ukraine</td>\n",
       "      <td>32.0</td>\n",
       "      <td>Shabri</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Unclear, keeps greening up and browing down</td>\n",
       "      <td>Fangjie</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Harvested 31/07/2022 and 29/08/2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (3623289.622 6596702.279)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>387.0</td>\n",
       "      <td>387.0</td>\n",
       "      <td>386.0</td>\n",
       "      <td>115320.0</td>\n",
       "      <td>661740.0</td>\n",
       "      <td>50.928689</td>\n",
       "      <td>31.637558</td>\n",
       "      <td>20.0</td>\n",
       "      <td>free_ukraine</td>\n",
       "      <td>69.0</td>\n",
       "      <td>Shabri</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Interesting</td>\n",
       "      <td>Fangjie</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Harvested 17/07/2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (3521885.751 6608675.134)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>306.0</td>\n",
       "      <td>306.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>543120.0</td>\n",
       "      <td>393504.0</td>\n",
       "      <td>48.307964</td>\n",
       "      <td>37.348245</td>\n",
       "      <td>20.0</td>\n",
       "      <td>free_ukraine</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Shabri</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Harvested 23/07/22</td>\n",
       "      <td>Blake</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23/07/22</td>\n",
       "      <td>POINT (4157596.478 6158229.471)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     fid    cat     id         x         y        lat        lon  strata  \\\n",
       "0  249.0  249.0  248.0 -321360.0  639156.0  50.655048  25.458684    20.0   \n",
       "1  165.0  165.0  164.0  447948.0  607452.0  50.294633  36.289471    20.0   \n",
       "2  400.0  400.0  399.0  179688.0  655860.0  50.860849  32.548484    20.0   \n",
       "3  387.0  387.0  386.0  115320.0  661740.0  50.928689  31.637558    20.0   \n",
       "4  306.0  306.0  305.0  543120.0  393504.0  48.307964  37.348245    20.0   \n",
       "\n",
       "            set  rd_id lab_set1  val_set1  \\\n",
       "0  free_ukraine   51.0   Shabri       1.0   \n",
       "1  free_ukraine   16.0   Shabri       0.0   \n",
       "2  free_ukraine   32.0   Shabri       2.0   \n",
       "3  free_ukraine   69.0   Shabri       0.0   \n",
       "4  free_ukraine    8.0   Shabri       1.0   \n",
       "\n",
       "                                      com_set1 lab_set2  val_set2  \\\n",
       "0                           Harvested 11/08/22    Josef       1.0   \n",
       "1                                       Spring    Josef       0.0   \n",
       "2  Unclear, keeps greening up and browing down  Fangjie       1.0   \n",
       "3                                  Interesting  Fangjie       1.0   \n",
       "4                           Harvested 23/07/22    Blake       0.0   \n",
       "\n",
       "                              com_set2 finHarvDat  \\\n",
       "0             Harvested 05/08-11/08/22   11/08/22   \n",
       "1                                  NaN        NaN   \n",
       "2  Harvested 31/07/2022 and 29/08/2022        NaN   \n",
       "3                 Harvested 17/07/2022        NaN   \n",
       "4                                  NaN   23/07/22   \n",
       "\n",
       "                          geometry  \n",
       "0  POINT (2834056.683 6560486.924)  \n",
       "1  POINT (4039734.283 6497444.336)  \n",
       "2  POINT (3623289.622 6596702.279)  \n",
       "3  POINT (3521885.751 6608675.134)  \n",
       "4  POINT (4157596.478 6158229.471)  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shapeFile = geopandas.read_file(\"../data/validation_data/merged_harvest_validation_20220919.shp\")\n",
    "shapeFile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         lat        lon finHarvDat  is_harvested  point_id\n",
      "0  50.655048  25.458684   11/08/22          True         0\n",
      "1  50.294633  36.289471        nan         False         1\n",
      "2  50.860849  32.548484        nan         False         2\n",
      "3  50.928689  31.637558        nan         False         3\n",
      "4  48.307964  37.348245   23/07/22          True         4 (558, 5)\n"
     ]
    }
   ],
   "source": [
    "points_from_sph_df = shapeFile[['lat', 'lon', 'val_set1', 'finHarvDat']].dropna(subset=['lat', 'lon', 'val_set1'])\n",
    "points_from_sph_df['is_harvested'] = points_from_sph_df['val_set1'].apply(lambda x: x == 1)\n",
    "points_from_sph_df = points_from_sph_df.drop(['val_set1'], axis=1)\n",
    "points_from_sph_df.finHarvDat = points_from_sph_df.finHarvDat.apply(lambda x: str(x))\n",
    "points_from_sph_df['point_id'] = np.arange(0, points_from_sph_df.shape[0], 1, dtype=int)\n",
    "print(points_from_sph_df.head(), points_from_sph_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_points(img: ee.Image, df:pandas.DataFrame, coordinate_col_names:(str, str)=('lon', 'lat')) -> ee.FeatureCollection:\n",
    "  \"\"\"\n",
    "  Overlays the points at df onto img. then, creates a table with the overlayed points(saved as ee.FeatureCollection).\n",
    "  The ee.FeatureCollection is exported into Drive in a GeoJson format.\n",
    "  So, the bands reflectances from img are put into the dataset described as the dataframe(df), then exported as .GeoJson.\n",
    "  \n",
    "  Args:\n",
    "      img (ee.Image): _description_\n",
    "      df (pandas.DataFrame): cointains longitude and latitude cols, describing the points to be overlayed.\n",
    "      coordinate_col_names (str, str, optional): the name of columns (in the dataframe df) that have the coordinates. Defaults to ('lon', 'lat').\n",
    "\n",
    "  Returns:\n",
    "      ee.FeatureCollection: _description_\n",
    "      \n",
    "  Usage:\n",
    "      export_to_drive(overlay_points(image, points_from_sph_df), 'points_from_sph')\n",
    "      # will save points_from_sph.geojson into drive.\n",
    "  \"\"\"\n",
    "  # Convert pandas dataframe to an ee.FeatureCollection\n",
    "  def createFeature(row):\n",
    "      lon = coordinate_col_names[0]\n",
    "      lat = coordinate_col_names[1]\n",
    "      geometry = ee.Geometry.Point([row[lon], row[lat]])\n",
    "      #print(df.columns.values)\n",
    "      dic = {}\n",
    "      for col_name in df.columns.values:\n",
    "        dic[col_name] = row[col_name]\n",
    "        \n",
    "      return ee.Feature(geometry, dic)\n",
    "\n",
    "  features = points_from_sph_df.apply(createFeature, axis=1).tolist()\n",
    "  fc = ee.FeatureCollection(features)\n",
    "\n",
    "\n",
    "  # Overlay the points on the imagery to get training.\n",
    "  overlayed_fc = img.sampleRegions(\n",
    "    collection= fc,\n",
    "    scale= 10 # maybe we should make this 10 instead\n",
    "  )\n",
    "  return overlayed_fc\n",
    "\n",
    "\n",
    "def export_to_drive(fc: ee.FeatureCollection, file:str, folder:str=\"NASA_Harvest\"):\n",
    "\n",
    "  # Export the ee.FeatureCollection as a .GeoJSON file.\n",
    "  task = ee.batch.Export.table.toDrive(**{\n",
    "    'collection': fc,\n",
    "    'description':file,\n",
    "    'fileFormat': 'GeoJSON',\n",
    "    'folder': folder\n",
    "  })\n",
    "  task.start()\n",
    "\n",
    "\n",
    "  print('----')\n",
    "  print(f'Polling for file name= {file}...')\n",
    "  while task.active():\n",
    "    time.sleep(5)\n",
    "  print(f'Wrote {file}.GeoJSON. Check {folder} folder in Drive.')\n",
    "  print('----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def read_geojson(file:str, date_col_name='finHarvDat') -> pandas.DataFrame:\n",
    "    \"\"\"\n",
    "        Expects the date column to have this format \"dd/mm/yy\", example: \"14/07/22\".\n",
    "        Expects that the file path looks like this: ../data/{file}.geojson\n",
    "    Args:\n",
    "        file (str): name of file (without the .geojson extention)\n",
    "        date_col_name (str, optional):\n",
    "        if df has no date column, pass None. Defaults to 'finHarvDat'.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame\n",
    "        \n",
    "    Usage:\n",
    "            read_geojson(file='points_from_sph').head()\n",
    "    \"\"\"\n",
    "\n",
    "    def to_datetime(string):\n",
    "        if(string == 'nan' or not string):\n",
    "            return None\n",
    "        splitted = string.split('/')\n",
    "        day = int(splitted[0])\n",
    "        month = int(splitted[1])\n",
    "        year = 2000 + int(splitted[2])\n",
    "        datetime_object = datetime(year=year, month = month, day=day)#datetime.strptime(string, '%d-%m-%Y')\n",
    "        return datetime_object\n",
    "    \n",
    "    df = geopandas.read_file(f\"../data/{file}.geojson\")\n",
    "    \n",
    "    if(date_col_name != None):\n",
    "        df[date_col_name] = df[date_col_name].apply(to_datetime)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create 3-week image collection from sentindel2 in 2022\n",
    "\n",
    "reference: https://medium.com/@moraesd90/creating-monthly-ndvi-composites-sentinel-2-on-google-earth-engine-a5c2d49bc9ca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(s2_img_collection: ee.ImageCollection) -> ee.Image:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        ee.image: a cloud masked sentinel-2 image.\n",
    "    \"\"\"\n",
    "    def cloudmask_and_clip(image: ee.Image) -> ee.Image:\n",
    "        opaqueClouds_mask = 1 << 10\n",
    "        cirrusClouds_mask =1 << 11\n",
    "        bit_mask =opaqueClouds_mask | cirrusClouds_mask\n",
    "        qa = image.select('QA60')\n",
    "        mask = qa.bitwiseAnd(bit_mask).eq(0)\n",
    "        return image.clip(COUNTRY_GEOMETRY).updateMask(mask)\n",
    "    \n",
    "    def add_ndvi(image):\n",
    "        ndvi = image.normalizedDifference(['B8', 'B4']).rename('NDVI')\n",
    "        image = image.addBands(ndvi.toFloat())\n",
    "        return image.toFloat()\n",
    "    \n",
    "    default_value = 0.0\n",
    "    image = s2_img_collection.map(cloudmask_and_clip).select(BANDS).filter(ee.Filter.lt(\"CLOUDY_PIXEL_PERCENTAGE\", 20)).median().unmask(default_value).float()\n",
    "    image = add_ndvi(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in the new image collection: 17\n"
     ]
    }
   ],
   "source": [
    "DATE_START = ee.Date('2022-01-01')\n",
    "DATE_END= ee.Date('2022-12-27')\n",
    "SURF_REF_SEN2 = ee.ImageCollection(\"COPERNICUS/S2_SR_HARMONIZED\").filterDate(DATE_START, DATE_END)\n",
    "\n",
    "# start_weeks.getInfo -> [1, 4, 7, 10, 13, 16, 19, 22, 25, 28, 31, 34, 37, 40, 43, 46, 49, 52]\n",
    "total_weeks = ee.Number(DATE_END.difference(DATE_START, 'week')).round().getInfo()\n",
    "start_weeks = ee.List.sequence(1, total_weeks, 3)\n",
    "\n",
    "def extract_subset(start_week):\n",
    "    \n",
    "    start = DATE_START.advance(start_week, 'week')\n",
    "    end = start.advance(3, 'week').advance(-1, 'day')\n",
    "    \n",
    "    def getCollection():\n",
    "        return SURF_REF_SEN2.filterDate(start, end)\n",
    "    \n",
    "    img_collection = getCollection()\n",
    "    return get_image(img_collection)\n",
    "    \n",
    "    \n",
    "\n",
    "# Map the extract_subset function over the list of start weeks to create a new image collection that contains the subsets of the original image collection\n",
    "new_img_collection = ee.ImageCollection.fromImages(start_weeks.map(extract_subset))\n",
    "num_of_images = new_img_collection.size().getInfo()\n",
    "# Print the number of images in the new image collection\n",
    "print('Number of images in the new image collection:', num_of_images)\n",
    "images_list = new_img_collection.toList(num_of_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ee.ee_list.List at 0x7fb45dd97ac0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ee' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m image \u001b[39m=\u001b[39m ee\u001b[39m.\u001b[39mImage(images_list\u001b[39m.\u001b[39mget(\u001b[39m6\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ee' is not defined"
     ]
    }
   ],
   "source": [
    "image = ee.Image(images_list.get(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<folium.map.LayerControl at 0x7fb45d9f0910>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vis_params = {\n",
    "  \"min\": 0,\n",
    "  \"max\": 3000,\n",
    "  \"bands\": [\"B4\", \"B3\", \"B2\"],\n",
    "}\n",
    "map = folium.Map(location=COUNTRY_LATLON, zoom_start=13)\n",
    "image=image.clip(COUNTRY_GEOMETRY)\n",
    "mapid = image.getMapId(vis_params)\n",
    "\n",
    "folium.TileLayer(\n",
    "    tiles=mapid['tile_fetcher'].url_format,\n",
    "    attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
    "    overlay=True,\n",
    "    name='median composite',\n",
    "  ).add_to(map)\n",
    "folium.LayerControl().add_to(map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n",
       "&lt;html&gt;\n",
       "&lt;head&gt;\n",
       "    \n",
       "    &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt;\n",
       "    \n",
       "        &lt;script&gt;\n",
       "            L_NO_TOUCH = false;\n",
       "            L_DISABLE_3D = false;\n",
       "        &lt;/script&gt;\n",
       "    \n",
       "    &lt;style&gt;html, body {width: 100%;height: 100%;margin: 0;padding: 0;}&lt;/style&gt;\n",
       "    &lt;style&gt;#map {position:absolute;top:0;bottom:0;right:0;left:0;}&lt;/style&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://code.jquery.com/jquery-1.12.4.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.0/css/all.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/gh/python-visualization/folium/folium/templates/leaflet.awesome.rotate.min.css&quot;/&gt;\n",
       "    \n",
       "            &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,\n",
       "                initial-scale=1.0, maximum-scale=1.0, user-scalable=no&quot; /&gt;\n",
       "            &lt;style&gt;\n",
       "                #map_98f6be4f4e3b0571e5a11cc054b0c48c {\n",
       "                    position: relative;\n",
       "                    width: 100.0%;\n",
       "                    height: 100.0%;\n",
       "                    left: 0.0%;\n",
       "                    top: 0.0%;\n",
       "                }\n",
       "                .leaflet-container { font-size: 1rem; }\n",
       "            &lt;/style&gt;\n",
       "        \n",
       "&lt;/head&gt;\n",
       "&lt;body&gt;\n",
       "    \n",
       "    \n",
       "            &lt;div class=&quot;folium-map&quot; id=&quot;map_98f6be4f4e3b0571e5a11cc054b0c48c&quot; &gt;&lt;/div&gt;\n",
       "        \n",
       "&lt;/body&gt;\n",
       "&lt;script&gt;\n",
       "    \n",
       "    \n",
       "            var map_98f6be4f4e3b0571e5a11cc054b0c48c = L.map(\n",
       "                &quot;map_98f6be4f4e3b0571e5a11cc054b0c48c&quot;,\n",
       "                {\n",
       "                    center: [50.0, 31.0],\n",
       "                    crs: L.CRS.EPSG3857,\n",
       "                    zoom: 13,\n",
       "                    zoomControl: true,\n",
       "                    preferCanvas: false,\n",
       "                }\n",
       "            );\n",
       "\n",
       "            \n",
       "\n",
       "        \n",
       "    \n",
       "            var tile_layer_50cdfd168817390121a3e3a1a9f46630 = L.tileLayer(\n",
       "                &quot;https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png&quot;,\n",
       "                {&quot;attribution&quot;: &quot;Data by \\u0026copy; \\u003ca target=\\&quot;_blank\\&quot; href=\\&quot;http://openstreetmap.org\\&quot;\\u003eOpenStreetMap\\u003c/a\\u003e, under \\u003ca target=\\&quot;_blank\\&quot; href=\\&quot;http://www.openstreetmap.org/copyright\\&quot;\\u003eODbL\\u003c/a\\u003e.&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 18, &quot;maxZoom&quot;: 18, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
       "            ).addTo(map_98f6be4f4e3b0571e5a11cc054b0c48c);\n",
       "        \n",
       "    \n",
       "            var tile_layer_5de4e961491ade08cc820e4cad87d63b = L.tileLayer(\n",
       "                &quot;https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/maps/36b523b6325f0ce5fa7ee4952c5dd983-6d1109094f64d2d51bfeac199e7c4af2/tiles/{z}/{x}/{y}&quot;,\n",
       "                {&quot;attribution&quot;: &quot;Map Data \\u0026copy; \\u003ca href=\\&quot;https://earthengine.google.com/\\&quot;\\u003eGoogle Earth Engine\\u003c/a\\u003e&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 18, &quot;maxZoom&quot;: 18, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
       "            ).addTo(map_98f6be4f4e3b0571e5a11cc054b0c48c);\n",
       "        \n",
       "    \n",
       "            var layer_control_60540696bad2fb7cae8ba485056e30a8 = {\n",
       "                base_layers : {\n",
       "                    &quot;openstreetmap&quot; : tile_layer_50cdfd168817390121a3e3a1a9f46630,\n",
       "                },\n",
       "                overlays :  {\n",
       "                    &quot;median composite&quot; : tile_layer_5de4e961491ade08cc820e4cad87d63b,\n",
       "                },\n",
       "            };\n",
       "            L.control.layers(\n",
       "                layer_control_60540696bad2fb7cae8ba485056e30a8.base_layers,\n",
       "                layer_control_60540696bad2fb7cae8ba485056e30a8.overlays,\n",
       "                {&quot;autoZIndex&quot;: true, &quot;collapsed&quot;: true, &quot;position&quot;: &quot;topright&quot;}\n",
       "            ).addTo(map_98f6be4f4e3b0571e5a11cc054b0c48c);\n",
       "        \n",
       "&lt;/script&gt;\n",
       "&lt;/html&gt;\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<folium.folium.Map at 0x7fb45db595e0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_end_dates = []\n",
    "start_weeks = ee.List.sequence(1, total_weeks, 3)\n",
    "\n",
    "# record the dates into start_end_dates array\n",
    "def eeDate_to_datetime(eeDate: ee.Date)->datetime:\n",
    "    year = eeDate.get('year').getInfo()\n",
    "    month = eeDate.get('month').getInfo()\n",
    "    day = eeDate.get('day').getInfo()\n",
    "    return datetime(year=year, month=month, day=day)\n",
    "\n",
    "for idx in range(num_of_images):\n",
    "    start_week = start_weeks.get(idx).getInfo()\n",
    "    start = DATE_START.advance(start_week, 'week')\n",
    "    end = start.advance(3, 'week').advance(-1, 'day')\n",
    "    start_end_dates.append((eeDate_to_datetime(start), eeDate_to_datetime(end)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((datetime.datetime(2022, 1, 8, 0, 0), datetime.datetime(2022, 1, 28, 0, 0)),\n",
       " 17)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_end_dates[0], len(start_end_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = [f'img{idx}_overlayed' for idx in range(num_of_images)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'echo'\n"
     ]
    }
   ],
   "source": [
    "%%script echo skipping\n",
    "\n",
    "# for each image, overylay the points(aka export to drive)\n",
    "for idx in range(num_of_images):\n",
    "    currImg = ee.Image(images_list.get(idx))\n",
    "    file = f'img{idx}_overlayed'\n",
    "    export_to_drive(overlay_points(currImg, points_from_sph_df),file=file )    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download From Drive & Move to 'data' Folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# true if (is_harvested is true) and if (the finHarvDat is within start_date & end_date)\n",
    "def get__is_within_period(row):\n",
    "    def date_within_range(dateToCheck:datetime, startDate:datetime, endDate:datetime):\n",
    "        \"\"\"credit: https://stackoverflow.com/users/22656/jon-skeet\"\"\"\n",
    "        return dateToCheck >= startDate and dateToCheck <= endDate\n",
    "    return row['is_harvested'] and date_within_range(row['finHarvDat'], row['start_date'], row['end_date'])\n",
    "    \n",
    "#samples = ee.List([]) # containing images\n",
    "samples = [None] * (num_of_images) # sample[0] is None\n",
    "\n",
    "path_inside_data_folder='overlayed_3week_images/'\n",
    "\n",
    "for idx in range(num_of_images):\n",
    "    curr_img_df = read_geojson(file=path_inside_data_folder + file_names[idx])\n",
    "    curr_img_df = curr_img_df.sort_values('point_id') # to make sure the points are aligned when we subtract ndvi values below\n",
    "    \n",
    "    # add time cols\n",
    "    start, end = start_end_dates[idx]\n",
    "    curr_img_df['start_date'] = np.tile(np.array([start]), curr_img_df.shape[0])\n",
    "    curr_img_df['end_date'] = np.tile(np.array([end]), curr_img_df.shape[0])\n",
    "    \n",
    "    curr_img_df['is_within_period'] = curr_img_df.apply(get__is_within_period, axis=1)\n",
    "    \n",
    "    curr_img_df['image_idx'] = np.tile(np.array(['i'+str(idx)]), curr_img_df.shape[0])\n",
    "    curr_img_df.rename(columns = {'point_id':'point_idx'}, inplace = True)\n",
    "    curr_img_df.point_idx = curr_img_df.point_idx.apply(lambda x: 'p' + str(x))\n",
    "    \n",
    "    samples[idx] = curr_img_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9486, 19)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_images = pandas.concat(samples, sort=False)\n",
    "merged_images = merged_images.drop(['geometry', 'id', 'is_harvested'], axis=1)\n",
    "merged_images[BANDS] /= 10000 # # divide by 10000 bc the bands are scaled by 10000\n",
    "                                #(according to https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S2)\n",
    "merged_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B11</th>\n",
       "      <th>B12</th>\n",
       "      <th>B2</th>\n",
       "      <th>B3</th>\n",
       "      <th>B4</th>\n",
       "      <th>B5</th>\n",
       "      <th>B6</th>\n",
       "      <th>B7</th>\n",
       "      <th>B8</th>\n",
       "      <th>B8A</th>\n",
       "      <th>NDVI</th>\n",
       "      <th>finHarvDat</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>point_idx</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>is_within_period</th>\n",
       "      <th>image_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2022-08-11</td>\n",
       "      <td>50.655048</td>\n",
       "      <td>25.458684</td>\n",
       "      <td>p0</td>\n",
       "      <td>2022-01-08</td>\n",
       "      <td>2022-01-28</td>\n",
       "      <td>False</td>\n",
       "      <td>i0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaT</td>\n",
       "      <td>50.294633</td>\n",
       "      <td>36.289471</td>\n",
       "      <td>p1</td>\n",
       "      <td>2022-01-08</td>\n",
       "      <td>2022-01-28</td>\n",
       "      <td>False</td>\n",
       "      <td>i0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaT</td>\n",
       "      <td>50.860849</td>\n",
       "      <td>32.548484</td>\n",
       "      <td>p2</td>\n",
       "      <td>2022-01-08</td>\n",
       "      <td>2022-01-28</td>\n",
       "      <td>False</td>\n",
       "      <td>i0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaT</td>\n",
       "      <td>50.928689</td>\n",
       "      <td>31.637558</td>\n",
       "      <td>p3</td>\n",
       "      <td>2022-01-08</td>\n",
       "      <td>2022-01-28</td>\n",
       "      <td>False</td>\n",
       "      <td>i0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1424</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0432</td>\n",
       "      <td>0.0631</td>\n",
       "      <td>0.0715</td>\n",
       "      <td>0.0776</td>\n",
       "      <td>0.0851</td>\n",
       "      <td>0.1066</td>\n",
       "      <td>0.1043</td>\n",
       "      <td>0.256335</td>\n",
       "      <td>2022-07-23</td>\n",
       "      <td>48.307964</td>\n",
       "      <td>37.348245</td>\n",
       "      <td>p4</td>\n",
       "      <td>2022-01-08</td>\n",
       "      <td>2022-01-28</td>\n",
       "      <td>False</td>\n",
       "      <td>i0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      B11     B12    B2      B3      B4      B5      B6      B7      B8  \\\n",
       "0  0.1000  0.1000  0.10  0.1000  0.1000  0.1000  0.1000  0.1000  0.1000   \n",
       "1  0.1000  0.1000  0.10  0.1000  0.1000  0.1000  0.1000  0.1000  0.1000   \n",
       "2  0.1000  0.1000  0.10  0.1000  0.1000  0.1000  0.1000  0.1000  0.1000   \n",
       "3  0.1000  0.1000  0.10  0.1000  0.1000  0.1000  0.1000  0.1000  0.1000   \n",
       "4  0.1424  0.1083  0.03  0.0432  0.0631  0.0715  0.0776  0.0851  0.1066   \n",
       "\n",
       "      B8A      NDVI finHarvDat        lat        lon point_idx start_date  \\\n",
       "0  0.1000  0.000000 2022-08-11  50.655048  25.458684        p0 2022-01-08   \n",
       "1  0.1000  0.000000        NaT  50.294633  36.289471        p1 2022-01-08   \n",
       "2  0.1000  0.000000        NaT  50.860849  32.548484        p2 2022-01-08   \n",
       "3  0.1000  0.000000        NaT  50.928689  31.637558        p3 2022-01-08   \n",
       "4  0.1043  0.256335 2022-07-23  48.307964  37.348245        p4 2022-01-08   \n",
       "\n",
       "    end_date  is_within_period image_idx  \n",
       "0 2022-01-28             False        i0  \n",
       "1 2022-01-28             False        i0  \n",
       "2 2022-01-28             False        i0  \n",
       "3 2022-01-28             False        i0  \n",
       "4 2022-01-28             False        i0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_images.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "366"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(merged_images.is_within_period) # we expect 366"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert pandas df to geopandas df\n",
    "merged_samples_gdf = geopandas.GeoDataFrame(\n",
    "    merged_images, geometry=geopandas.points_from_xy(merged_images.lon, merged_images.lat))\n",
    "\n",
    "# save dataset\n",
    "merged_samples_gdf.to_file('../data/merged_images.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('harvest-event-detec-Fyp2lGEN-py3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0cf1faa60ab086dde8d867eb16c20b4bffc52bbf785c13cdda65e2052ce97abb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
